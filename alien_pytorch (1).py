# -*- coding: utf-8 -*-
"""Alien_Pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M1Ra2H4ql158MI4_B4ggOFmYsLZLuu1Z
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
#import torchvision
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models

import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from PIL import Image
import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt
import os

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay

from google.colab import drive
drive.mount('/content/drive')

import os
zip_path = '/content/drive/My Drive/Colab_Notebooks/archive.zip'
extract_path = '/content/drive/My Drive/Colab_Notebooks/alien_predator_dataset'

# Create extraction path if it doesn't exist
os.makedirs(extract_path, exist_ok=True)

# unzip file
!unzip -q "{zip_path}" -d "{extract_path}"

# path
path = os.path.join(extract_path, 'data')


# transforms for train and test sets
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

train_dataset = datasets.ImageFolder(path + '/train', transform=train_transform)
test_dataset = datasets.ImageFolder(path + '/validation', transform=test_transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

train_set_size, test_set_size = len(train_dataset), len(test_dataset)
print('Train size:', train_set_size, '\nTest size:', test_set_size)

model = models.resnet50(pretrained=True)

num_classes = len(train_dataset.classes)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, num_classes)

print(model)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.fc.parameters(), lr=0.0001)

# training
num_epochs = 3

for epoch in range(num_epochs):
    model.train()  # set model to training mode
    running_loss = 0.0
    for images, labels in train_loader:
        optimizer.zero_grad() # clear the gradients
        outputs = model(images) # get outputs
        loss = criterion(outputs, labels) # calculate loss
        loss.backward() # backpropagation
        optimizer.step() # update weights

        running_loss += loss.item() * images.size(0)

    # print loss
    epoch_loss = running_loss / len(train_dataset)
    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}")

    # validation phase
    model.eval()  # set model to evaluation mode
    with torch.no_grad(): # disable gradient calculations to speed up computations
        correct = 0
        total = 0
        for images, labels in test_loader:
            outputs = model(images) # get raw outputs (logits)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
        # print accuracy
        accuracy = correct / total
        print(f"Validation Accuracy: {accuracy:.4f}")

# save the trained model
!mkdir pytorch_models
torch.save(model.state_dict(), 'pytorch_models/tomato_resnet_model.pth')

all_labels =[]
all_preds=[]

with torch.no_grad():
  for images, labels in test_loader:
    images, labels = images, labels
    outputs = model(images)
    _, predicted = torch.max(outputs.data, 1)
    all_labels.extend(labels.cpu().numpy())
    all_preds.extend(predicted.cpu().numpy())

# convert to numpy arrays
y_true = np.array(all_labels)
y_pred = np.array(all_preds)

# print metrics
labels =['Alien','Predetor']
print(classification_report(y_true, y_pred,target_names=labels))

# confusion matrix
cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
disp.plot(cmap=plt.cm.Blues)
plt.show()

"""Prediction"""

# create new model trained by the saved model
model = models.resnet50(pretrained=False)
num_classes = len(train_dataset.classes)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, num_classes)
model.load_state_dict(torch.load('pytorch_models/tomato_resnet_model.pth'))
# set model to evaluation mode
model.eval()

# list images
validation_img_paths = ["/validation/alien/11.jpg",
                        "/validation/alien/22.jpg",
                        "/validation/predator/33.jpg"]
img_list = [Image.open(path + img_path) for img_path in validation_img_paths]

# transform the applied images and stacks the transformed images into a single batch
validation_batch = torch.stack([test_transform(img)
                                for img in img_list])

# get logits
pred_logits_tensor = model(validation_batch)
pred_logits_tensor

# get probabilities
pred_probs = F.softmax(pred_logits_tensor, dim=1).data.numpy()
pred_probs

# show result
fig, axs = plt.subplots(1, len(img_list), figsize=(20, 5))
for i, img in enumerate(img_list):
    ax = axs[i]
    ax.axis('off')
    ax.set_title("{:.0f}% Alien, {:.0f}% Predator".format(100*pred_probs[i,0],
                                                            100*pred_probs[i,1]))
    ax.imshow(img)





